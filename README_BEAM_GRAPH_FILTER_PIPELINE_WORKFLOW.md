# ğŸ—ï¸ Beam Graph Filter Pipeline â€“ Detailed Workflow

TÃ i liá»‡u nÃ y mÃ´ táº£ **toÃ n bá»™ luá»“ng xá»­ lÃ½** cá»§a script `beam_graph_filter_pipeline.py`, tá»« khi nháº­p lá»‡nh CLI Ä‘áº¿n khi sinh ra 3 file káº¿t quáº£.

---

## 1. Chuáº©n bá»‹ & Tham sá»‘ CLI

```bash
python beam_graph_filter_pipeline.py \
    --input raw_test.json \
    --output_dir beam_filter_output \
    --beam_width 80 \
    --max_depth 300 \
    --max_paths 500 \
    --beam_sentences 400 \
    --min_relevance 0.15 \
    --max_final_sentences 30
```

| Flag | Máº·c Ä‘á»‹nh | Ã nghÄ©a |
|------|----------|---------|
| `--input` | `raw_test.json` | File JSON Ä‘áº§u vÃ o (list sample) |
| `--output_dir` | `beam_filter_output` | ThÆ° má»¥c ghi káº¿t quáº£ |
| `--beam_width` | 40 | Sá»‘ path giá»¯ láº¡i má»—i bÆ°á»›c trong beam search |
| `--max_depth` | 120 | Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a má»™t path |
| `--max_paths` | 200 | Tá»•ng sá»‘ path tá»‘t nháº¥t tráº£ vá» |
| `--beam_sentences` | 50 | Sá»‘ cÃ¢u láº¥y ra tá»« beam search trÆ°á»›c khi lá»c |
| `--min_relevance` | 0.15 | NgÆ°á»¡ng Ä‘iá»ƒm liÃªn quan giá»¯ cÃ¢u á»Ÿ Stage 1 |
| `--max_final_sentences` | 30 | Sá»‘ cÃ¢u cuá»‘i cÃ¹ng sau Advanced Filter |

---

## 2. Luá»“ng Xá»­ LÃ½ Tá»•ng QuÃ¡t

```mermaid
graph TD
  A[CLI Args] --> B[Load Samples]
  B --> C{Loop Samples}
  C --> D[Pre-process & Split]
  D --> E[VnCoreNLP Annotation]
  E --> F[Build TextGraph]
  F --> G[Beam Search]
  G --> H{sentences?}
  H -->|Yes| I[Candidate Sentences]
  H -->|No| J[Fallback Raw Sentences]
  I --> K[Advanced Data Filter]
  J --> K
  K --> L[Collect Results]
  L --> C
  C --> M[Dump simple.json / detailed.json / stats.json]
```

---

## 3. Chi tiáº¿t tá»«ng giai Ä‘oáº¡n

### 3.1 Pre-process
* Chuáº©n hoÃ¡ Unicode, dáº¥u cÃ¢u, khoáº£ng tráº¯ng (`clean_text`).
* TÃ¡ch cÃ¢u regex (`split_sentences`).

### 3.2 Annotation (VnCoreNLP)
* Tokenize, POS, NER, Dependency cho **context** vÃ  **claim**.

### 3.3 XÃ¢y TextGraph
* Node: `word`, `sentence`, `claim`.
* Edge: structural (word â†” sentence/claim), dependency (word â†” word), entity.

### 3.4 Beam Search
* TÃ¬m path tá»« **claim node** Ä‘áº¿n **sentence nodes**.
* Giá»¯ `beam_width` path/khoáº£ng; dá»«ng á»Ÿ `max_depth`.
* Tráº£ vá» tá»‘i Ä‘a `max_paths` path tá»‘t nháº¥t (scoring ná»™i bá»™).
* `extract_sentences_from_paths` láº¥y `beam_sentences` cÃ¢u cao Ä‘iá»ƒm nháº¥t Ä‘á»ƒ tiáº¿p tá»¥c.

### 3.4.1 CÆ¡ cháº¿ bÃªn trong Beam Search
**Thuáº­t toÃ¡n:**
1. Báº¯t Ä‘áº§u tá»« **claim node**.
2. Má»Ÿ rá»™ng táº¥t cáº£ neighbor (word / entity / sentence) â†’ táº¡o **path á»©ng viÃªn**.
3. TÃ­nh `score_path(path)` â€“ káº¿t há»£p:
   * *Keyword overlap* giá»¯a words trong path & claim (0-1).
   * *Fuzzy similarity* claim â†” sentence cuá»‘i path (0-1).
   * *Path length penalty* (thÆ°á»Ÿng Ä‘Æ°á»ng ngáº¯n).
   * *Entity bonus* (náº¿u path Ä‘i qua entity node).
4. Giá»¯ **`beam_width`** path Ä‘iá»ƒm cao nháº¥t.
5. Láº·p tá»›i `max_depth` bÆ°á»›c hoáº·c khi Ä‘á»§ **`max_paths`**.
6. Tráº£ vá» danh sÃ¡ch path, Ä‘Ã£ sort giáº£m dáº§n theo `score`.

> Thá»±c thi bá»Ÿi lá»›p `BeamSearchPathFinder` (mint/beam_search.py). HÃ m chÃ­nh:
> * `find_best_paths()` âŸ¶ tráº£ vá» top-N path.

### 3.5 Fallback (khÃ´ng cÃ³ path)
Náº¿u Beam Search ra 0 cÃ¢u â†’ dÃ¹ng toÃ n bá»™ cÃ¢u gá»‘c (Ä‘Ã£ tÃ¡ch) lÃ m candidate.

### 3.6 Advanced Data Filter (ADF)
| Stage | MÃ´ táº£ | Báº­t/Táº¯t |
|-------|-------|---------|
| 1 | **Semantic Relevance Filtering** â€“ keyword overlap, topic coherence, SBERT (náº¿u cÃ³) | luÃ´n |
| 2 | **Entity-Based Filtering** â€“ giá»¯ cÃ¢u chá»©a entity liÃªn quan | khi truyá»n `entities` |
| 3 | **Contradiction / Stance Detection** â€“ SBERT hoáº·c NLI | khi `use_contradiction_detection` |
| 4 | **Duplicate Removal & Ranking** â€“ xoÃ¡ cÃ¢u trÃ¹ng, tÃ­nh `confidence_score`, cáº¯t cÃ²n `max_final_sentences` | luÃ´n |

> Vá»›i cáº¥u hÃ¬nh default (khÃ´ng SBERT, khÃ´ng NLI, khÃ´ng entity) chá»‰ Stage 1 vÃ  4 hoáº¡t Ä‘á»™ng.

### 3.6.1 PhÃ¢n rÃ£ cÃ´ng thá»©c & logic AdvancedDataFilter
| Stage | TÃªn hÃ m | Äiá»ƒm chÃ­nh |
|-------|---------|------------|
| 1 | `_stage2_semantic_relevance_filtering` | *relevance_score* = 0.6Ã—keyword_overlap + 0.4Ã—topic_coherence (hoáº·c 0.4/0.4/0.2 khi cÃ³ SBERT). Giá»¯ cÃ¢u `â‰¥ min_relevance_score`. |
| 2 | `_stage3_entity_based_filtering` | *entity_score* = 0.6Ã—frequency + 0.4Ã—relevance_to_claim. Bá» náº¿u khÃ´ng truyá»n `entities`. |
| 3 | `_stage4_contradiction_detection` | So cosine(SBERT) giá»¯a cÃ¢u vÃ  claim (vs. negated-claim) â†’ phÃ¢n loáº¡i `support/refute`; loáº¡i *neutral*. |
| 4 | `_stage5_duplicate_removal_and_ranking` | *confidence_score* = 0.2 quality + 0.3 relevance + 0.2 entity + 0.2 (1-contradiction) + 0.1 original_beam_score. Sort & cáº¯t `max_final_sentences`. |

**Quality score** (dÃ¹ng á»Ÿ Stage 4):
* Äá»™ dÃ i tá»‘i Æ°u (5-50 tá»«).
* *Information density* (tá»« meaningful / tá»•ng tá»«).
* *Sentence structure* (cÃ³ Subject-Verb, v.v.).
* *Content richness* (Ä‘a dáº¡ng tá»«/ngá»¯).  
`quality_score = 0.3 length + 0.3 density + 0.2 structure + 0.2 richness`.

> File nguá»“n: `advanced_data_filtering.py`. Báº¡n cÃ³ thá»ƒ chá»‰nh *weights* tuá»³ nhu cáº§u.

### 3.6.2 Lá»c **leftover_sentences** (ngoÃ i Beam)
Tá»« v1.1, script sáº½:
1. So sÃ¡nh danh sÃ¡ch cÃ¢u gá»‘c (`raw_sentences`) vá»›i `candidate_sentences`.
2. Nhá»¯ng cÃ¢u **khÃ´ng xuáº¥t hiá»‡n** trong candidate â†’ `leftover_sentences`.
3. Cháº¡y `AdvancedDataFilter` **má»™t láº§n ná»¯a** cho nhÃ³m nÃ y.
4. Gá»™p káº¿t quáº£ `extra` vÃ o `final_sentences`, trÃ¡nh trÃ¹ng láº·p.

â†’ Äáº§u ra cuá»‘i cÃ¹ng = cÃ¢u qua Beam + cÃ¢u ngoÃ i Beam nhÆ°ng Ä‘á»§ Ä‘iá»ƒm relevance.

---

### 3.7 Collect & Append
* Táº¡o `simple_result` (context, claim, evidence list).
* Táº¡o `detailed_result` (thÃªm Ä‘iá»ƒm sá»‘ + thá»‘ng kÃª beam).
* Append vÃ o `simple_outputs`, `detailed_outputs`.

### 3.8 Xuáº¥t file
* Sau khi xá»­ lÃ½ xong táº¥t cáº£ sample:
  * `_simple.json`â€ƒmáº£ng `simple_result`.
  * `_detailed.json` máº£ng `detailed_result`.
  * `_stats.json`â€ƒ thá»‘ng kÃª tá»•ng (sá»‘ cÃ¢u, thÃ´ng sá»‘ beam).

---

## 4. Tips tá»‘i Æ°u

| Má»¥c tiÃªu | Gá»£i Ã½ |
|----------|-------|
| TÄƒng Ä‘á»™ phá»§ cÃ¢u (>90 %) | TÄƒng `beam_sentences`, `beam_width`, `max_paths`. Äáº·t `beam_sentences=-1` Ä‘á»ƒ khÃ´ng giá»›i háº¡n. |
| Giáº£m thá»i gian cháº¡y | Giáº£m `max_depth`, giáº£m `beam_width`, bá» SBERT/NLI. |
| Ghi káº¿t quáº£ tá»«ng sample ngay | Sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng **JSON Lines** (`.jsonl`) vÃ  má»Ÿ file vá»›i mode `"a"`. |
| Táº¯t/ báº­t SBERT | `use_sbert=True` khi khá»Ÿi táº¡o `AdvancedDataFilter` (Ä‘áº£m báº£o `sentence-transformers`). |

---

## 5. Chuyá»ƒn Ä‘á»•i JSON Lines â†’ Array
Náº¿u dÃ¹ng cháº¿ Ä‘á»™ `jsonl` vÃ  muá»‘n gá»™p thÃ nh máº£ng:
```bash
jq -s '.' raw_test_beam_filtered_0.15_*.jsonl > merged_simple.json
```

---

## 6. LiÃªn há»‡ & ÄÃ³ng gÃ³p
* Issue / PR luÃ´n hoan nghÃªnh!
* TuÃ¢n thá»§ quy táº¯c commit: `feat:`, `fix:`, `docs:`, `refactor:`.

MIT License Â© 2025 â€“ BGFP Team 

## 7. Cháº¡y thá»­ nhanh
```bash
python beam_graph_filter_pipeline.py \
  --input raw_test.json \
  --output_dir demo_output \
  --beam_width 80 \        # theo config benchmark
  --max_depth 300 \        # path dÃ i hÆ¡n, phá»§ rá»™ng hÆ¡n
  --max_paths 500 \        # Ä‘á»§ nhiá»u path
  --beam_sentences 400 \   # láº¥y 400 cÃ¢u trÆ°á»›c khi lá»c
  --max_final_sentences 50 \
  --min_relevance 0.15 \
  --max_samples 5          # demo 5 sample Ä‘áº§u
```
Sau khi cháº¡y, báº¡n sáº½ tháº¥y:
* `demo_output/*_simple.json` â€“ danh sÃ¡ch evidence (Ä‘Ã£ gá»™p leftover).
* `demo_output/*_detailed.json` â€“ Ä‘iá»ƒm sá»‘ & metadata.
* `demo_output/*_stats.json` â€“ thá»‘ng kÃª tá»•ng.
