# ğŸ” Beam Search Filter Pipeline

> **Comprehensive Vietnamese text processing framework for fact-checking and information retrieval using beam search and advanced filtering techniques**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Documentation](https://img.shields.io/badge/Docs-Complete-brightgreen.svg)](docs/README_INDEX.md)

## ğŸ“‹ **Overview**

Beam Search Filter Pipeline lÃ  má»™t framework toÃ n diá»‡n cho viá»‡c xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t, táº­p trung vÃ o fact-checking vÃ  information retrieval. Framework sá»­ dá»¥ng beam search algorithm káº¿t há»£p vá»›i advanced filtering techniques Ä‘á»ƒ tÃ¬m vÃ  lá»c cÃ¡c cÃ¢u liÃªn quan tá»« context dá»±a trÃªn claim.

### **Core Capabilities**

* ğŸ” **Vietnamese NLP**: VnCoreNLP integration cho text annotation
* ğŸ•¸ï¸ **Graph-based Search**: NetworkX-based text graph vá»›i beam search
* ğŸ”„ **Advanced Filtering**: SBERT, contradiction detection, NLI stance detection
* ğŸ—ï¸ **Modular Design**: Clean, maintainable, vÃ  extensible architecture
* ğŸ–¥ï¸ **CLI Interface**: Easy-to-use command-line interface
* ğŸ **Python API**: Flexible programming interface

## ğŸš€ **Quick Start**

### **Task 1: Basic Pipeline Usage**

```bash
# Run with default settings
python run_pipeline.py

# Use CLI interface
python src/pipeline/cli.py context.txt claim.txt output.json
```

### **Task 2: Custom Configuration**

```python
from src.pipeline.beam_filter_pipeline import BeamFilterPipeline

# Custom configuration
config = {
    "beam_width": 50,
    "max_depth": 100,
    "min_relevance_score": 0.2,
    "max_final_sentences": 20,
    "use_sbert": True
}

pipeline = BeamFilterPipeline(config)
results = pipeline.run_pipeline(context, claim)
```

### **Task 3: Advanced Filtering**

```bash
# Enable advanced filtering features
python src/pipeline/cli.py \
    --use-sbert \
    --use-contradiction-detection \
    --use-nli \
    context.txt claim.txt output.json
```

### **Task 4: Output Files**

Pipeline táº¡o ra **3 loáº¡i output file**:

```bash
# Run pipeline
python run_pipeline.py --input raw_test.json --min_relevance 0.15

# Output files generated:
# â€¢ raw_test_beam_filtered_0.15_20241201_143022_detailed.json
# â€¢ raw_test_beam_filtered_0.15_20241201_143022_simple.json  
# â€¢ raw_test_beam_filtered_0.15_20241201_143022_stats.json
```

**File Types:**
- **Detailed**: ThÃ´ng tin chi tiáº¿t vá» quÃ¡ trÃ¬nh xá»­ lÃ½
- **Simple**: Chá»‰ cÃ³ danh sÃ¡ch evidence sentences
- **Stats**: Thá»‘ng kÃª tá»•ng quan vá» processing

## ğŸ“Š **Performance Guidelines**

| Text Size | Beam Width | Max Depth | Min Relevance | Max Sentences | Expected Time |
|-----------|------------|-----------|---------------|---------------|---------------|
| **Small** (< 500 words) | 30 | 80 | 0.2 | 15 | ~30s |
| **Medium** (500-2000 words) | 40 | 120 | 0.15 | 30 | ~60s |
| **Large** (> 2000 words) | 50 | 150 | 0.1 | 50 | ~120s |

## ğŸ—ï¸ **Project Architecture**

### **Core Components**

```
src/                           # Refactored modules
â”œâ”€â”€ utils/                     # Text preprocessing utilities
â”‚   â””â”€â”€ text_preprocessor.py   # Text cleaning & sentence splitting
â”œâ”€â”€ nlp/                       # NLP wrapper
â”‚   â””â”€â”€ vncorenlp_wrapper.py  # VnCoreNLP integration
â”œâ”€â”€ graph/                     # Simplified graph
â”‚   â””â”€â”€ text_graph_simple.py  # TextGraph for pipeline
â”œâ”€â”€ filtering/                 # Filter wrapper
â”‚   â””â”€â”€ filter_wrapper.py     # AdvancedDataFilter wrapper
â””â”€â”€ pipeline/                  # Main pipeline
    â”œâ”€â”€ beam_filter_pipeline.py # Main pipeline class
    â””â”€â”€ cli.py                # CLI interface

mint/                          # Original modules (preserved)
â”œâ”€â”€ text_graph.py             # Full-featured graph
â”œâ”€â”€ beam_search.py            # Beam search algorithm
â””â”€â”€ helpers.py                # Helper functions

advanced_data_filtering.py     # Advanced filtering system
```

### **Workflow Architecture**

```
Input Text â†’ Preprocessing â†’ NLP Annotation â†’ Graph Building â†’ Beam Search â†’ Filtering â†’ Output
     â†“              â†“              â†“              â†“              â†“           â†“
  Clean Text   VnCoreNLP    Text Graph    Path Finding   Relevance   Final Sentences
```

## ğŸ“š **Comprehensive Documentation**

* **[ğŸ“– Complete Documentation](docs/README_INDEX.md)**: Full documentation index
* **[ğŸ—ï¸ Architecture Overview](README_REFACTORED.md)**: Project architecture details
* **[ğŸ§  VnCoreNLP Setup](docs/VNCORENLP_SETUP.md)**: Vietnamese NLP installation guide
* **[ğŸ”§ Module Documentation](docs/)**: Individual module documentation
* **[ğŸ“š Original Files](docs/README_ORIGINAL_FILES.md)**: Migration and backward compatibility

## ğŸ¯ **Use Cases**

### **Fact-Checking Pipeline**
```python
# Extract relevant sentences for fact-checking
pipeline = BeamFilterPipeline()
results = pipeline.run_pipeline(context, claim)
relevant_sentences = results["final_sentences"]
```

### **Information Retrieval**
```python
# Find sentences related to a specific claim
config = {"beam_width": 60, "max_depth": 150}
pipeline = BeamFilterPipeline(config)
results = pipeline.run_pipeline(context, query)
```

### **Text Analysis**
```python
# Analyze text structure and relationships
from src.graph.text_graph_simple import TextGraphSimple
graph = TextGraphSimple()
# ... build and analyze graph
```

### **Batch Processing**
```bash
# Process multiple files
for file in contexts/*.txt; do
    python src/pipeline/cli.py "$file" claims/$(basename "$file") output/$(basename "$file" .txt).json
done
```

## ğŸ”§ **Configuration**

### **Environment Setup**

```bash
# Clone repository
git clone <repository-url>
cd BeamSearchFillter

# Install dependencies
pip install -r requirements.txt

# Setup environment
cp .env.example .env
# Edit .env and add your OpenAI API key if needed

# Optional: Install VnCoreNLP for Vietnamese processing
# See [VnCoreNLP Setup Guide](docs/VNCORENLP_SETUP.md)
# Or use auto setup: ./setup_vncorenlp.sh
```

### **Pipeline Configuration**

```python
config = {
    "beam_width": 40,              # Beam search width
    "max_depth": 120,              # Maximum search depth
    "max_paths": 200,              # Maximum paths to find
    "min_relevance_score": 0.15,   # Minimum relevance for filtering
    "max_final_sentences": 30,     # Maximum final sentences
    "use_sbert": False,            # Enable SBERT filtering
    "use_contradiction_detection": False,  # Enable contradiction detection
    "use_nli": False,              # Enable NLI stance detection
    "enable_pos_filtering": True,  # Enable POS tag filtering
    "important_pos_tags": {"N", "Np", "V", "A", "Nc", "M", "R", "P"}
}
```

### **CLI Options**

```bash
python src/pipeline/cli.py \
    --beam-width 50 \
    --max-depth 100 \
    --min-relevance 0.2 \
    --max-final-sentences 20 \
    --use-sbert \
    context.txt claim.txt output.json
```

## ğŸ› ï¸ **Advanced Features**

### **Implemented Capabilities**

* âœ… **Vietnamese NLP Processing**: Full VnCoreNLP integration
* âœ… **Graph-based Search**: NetworkX text graph vá»›i beam search
* âœ… **Multi-stage Filtering**: SBERT, contradiction, NLI filtering
* âœ… **Modular Architecture**: Clean separation of concerns
* âœ… **CLI Interface**: Complete command-line tools
* âœ… **Python API**: Flexible programming interface
* âœ… **Error Handling**: Comprehensive error handling vÃ  fallbacks
* âœ… **Documentation**: Complete documentation vá»›i examples

### **Research Applications**

* **Fact-checking Research**: Extract relevant evidence tá»« large texts
* **Information Retrieval**: Find related sentences cho specific queries
* **Text Analysis**: Analyze text structure vÃ  relationships
* **Vietnamese NLP**: Study Vietnamese text processing techniques

## ğŸ“ˆ **Output Formats**

Pipeline táº¡o ra **3 loáº¡i output file** vá»›i format tÃªn file: `{input_name}_beam_filtered_{min_relevance}_{timestamp}_{type}.json`

### **1. Detailed Output** (`*_detailed.json`)
Chá»©a thÃ´ng tin chi tiáº¿t vá» quÃ¡ trÃ¬nh xá»­ lÃ½:
```json
[
  {
    "context": "Original context text",
    "claim": "Original claim text",
    "multi_level_evidence": [
      {
        "sentence": "Final sentence 1",
        "relevance_score": 0.92,
        "beam_score": 0.85,
        "path": ["claim_0", "word_1", "sentence_0"]
      }
    ],
    "statistics": {
      "beam": {
        "total_paths": 15,
        "unique_sentences": 25
      }
    }
  }
]
```

### **2. Simple Output** (`*_simple.json`)
Chá»©a káº¿t quáº£ Ä‘Æ¡n giáº£n, chá»‰ cÃ³ evidence sentences:
```json
[
  {
    "context": "Original context text",
    "claim": "Original claim text",
    "multi_level_evidence": [
      "Final sentence 1",
      "Final sentence 2",
      "Final sentence 3"
    ]
  }
]
```

### **3. Statistics Output** (`*_stats.json`)
Chá»©a thá»‘ng kÃª tá»•ng quan vá» quÃ¡ trÃ¬nh xá»­ lÃ½:
```json
{
  "total_context_sentences": 6442,
  "total_beam_sentences": 4933,
  "total_final_sentences": 4933,
  "num_samples": 300,
  "beam_parameters": {
    "beam_width": 80,
    "max_depth": 300,
    "max_paths": 500,
    "beam_sentences": 400
  }
}
```

### **Console Output**
```
ğŸ”§ Beam Search Filter Pipeline - Default Run
=====================================

ğŸ“ Input:
Context: SAWACO thÃ´ng bÃ¡o táº¡m ngÆ°ng cung cáº¥p nÆ°á»›c tá»« 22 giá» Ä‘áº¿n 4 giá».
Claim: SAWACO thÃ´ng bÃ¡o táº¡m ngÆ°ng cung cáº¥p nÆ°á»›c.

ğŸ”„ Running pipeline...
âœ… Pipeline completed in 2.34s

ğŸ“Š Results:
- Found 2 relevant sentences
- Graph: 45 nodes, 89 edges
- Beam search: 15 paths found
- Filtering: 15 â†’ 2 sentences

ğŸ¯ Final Sentences:
1. SAWACO thÃ´ng bÃ¡o táº¡m ngÆ°ng cung cáº¥p nÆ°á»›c tá»« 22 giá» Ä‘áº¿n 4 giá».
2. CÃ¡c khu vá»±c bá»‹ áº£nh hÆ°á»Ÿng gá»“m quáº­n 6, 8, 12.

âœ… Done! Output saved to:
   â€¢ raw_test_beam_filtered_0.15_20241201_143022_detailed.json
   â€¢ raw_test_beam_filtered_0.15_20241201_143022_simple.json
   â€¢ raw_test_beam_filtered_0.15_20241201_143022_stats.json
```

## ğŸ”— **Dependencies**

### **Required**
- `networkx`: Graph data structure
- `typing`: Type hints
- `argparse`: Command-line argument parsing
- `mint.beam_search`: Beam search algorithm (existing)
- `advanced_data_filtering`: Filter system (existing)

### **Optional**
- `py_vncorenlp`: Vietnamese NLP toolkit
- `vncorenlp/`: VnCoreNLP models directory
- `sentence-transformers`: For SBERT filtering
- `transformers`: For NLI and contradiction detection

## ğŸ§ª **Testing**

### **Quick Test**
```bash
# Test basic functionality
python run_pipeline.py

# Test CLI
python src/pipeline/cli.py test_context.txt test_claim.txt test_output.json
```

### **Comprehensive Test**
```bash
# Test with examples
python example_usage.py
```

## ğŸ” **Troubleshooting**

### **Common Issues**

**1. VnCoreNLP not available:**
```bash
# Check VnCoreNLP installation
ls -la vncorenlp/
python -c "from py_vncorenlp import py_vncorenlp; print('VnCoreNLP available')"
```

**2. AdvancedDataFilter not found:**
```bash
# Check if file exists
ls -la advanced_data_filtering.py
```

**3. Memory issues:**
```python
# Reduce parameters
config = {
    "beam_width": 20,
    "max_depth": 60,
    "max_paths": 100,
    "max_final_sentences": 15
}
```

## ğŸ“ **Contributing**

Beam Search Filter Pipeline welcomes contributions in:

* **New filtering methods**: Additional sentence filtering algorithms
* **Graph algorithms**: Novel beam search approaches
* **Vietnamese NLP**: Enhanced text processing techniques
* **Evaluation metrics**: Advanced relevance measures
* **Performance optimization**: More efficient processing patterns

### **Code Style**
- Follow existing module structure
- Use type hints
- Include comprehensive error handling
- Add documentation for new functions

## ğŸ“ **Support**

* **Documentation**: [docs/README_INDEX.md](docs/README_INDEX.md)
* **Issues**: Check troubleshooting sections in module docs
* **Migration**: See [docs/README_ORIGINAL_FILES.md](docs/README_ORIGINAL_FILES.md)

## ğŸ“œ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

ğŸš€ **Happy Vietnamese Text Processing!** Whether you're doing fact-checking research, information retrieval, or Vietnamese NLP development, Beam Search Filter Pipeline provides comprehensive tools for Vietnamese text intelligence research.

## About

> **Comprehensive Vietnamese text processing framework for fact-checking and information retrieval using beam search and advanced filtering techniques**

### Topics

- `nlp` - Natural Language Processing
- `vietnamese` - Vietnamese language processing
- `fact-checking` - Fact verification and validation
- `beam-search` - Graph-based search algorithms
- `text-filtering` - Advanced text filtering techniques

### Resources

- [ğŸ“– Complete Documentation](docs/README_INDEX.md)
- [ğŸ—ï¸ Architecture Overview](README_REFACTORED.md)
- [ğŸ§  VnCoreNLP Setup](docs/VNCORENLP_SETUP.md)

### License

MIT license 