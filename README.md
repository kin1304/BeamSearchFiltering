# ğŸ” Beam Search Filter Pipeline

> **Comprehensive Vietnamese text processing framework for fact-checking and information retrieval using beam search and advanced filtering techniques**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Documentation](https://img.shields.io/badge/Docs-Complete-brightgreen.svg)](docs/README_INDEX.md)

## ğŸ“‹ **Overview**

Beam Search Filter Pipeline is a comprehensive framework for Vietnamese text processing, focusing on fact-checking and information retrieval. The framework uses beam search algorithms combined with advanced filtering techniques to find and filter relevant sentences from context based on claims.

### **Core Capabilities**

* ğŸ” **Vietnamese NLP**: VnCoreNLP integration for text annotation
* ğŸ•¸ï¸ **Graph-based Search**: NetworkX-based text graph with beam search
* ğŸ”„ **Advanced Filtering**: SBERT, contradiction detection, NLI stance detection
* ğŸ—ï¸ **Modular Design**: Clean, maintainable, and extensible architecture
* ğŸ–¥ï¸ **CLI Interface**: Easy-to-use command-line interface
* ğŸ **Python API**: Flexible programming interface

## ğŸš€ **Quick Start**

### **Task 1: Basic Pipeline Usage**

```bash
# Run with default settings
python run_pipeline.py

# Use CLI interface
python src/pipeline/cli.py context.txt claim.txt output.json
```

### **Task 2: Custom Configuration**

```python
from src.pipeline.beam_filter_pipeline import BeamFilterPipeline

# Custom configuration
config = {
    "beam_width": 50,
    "max_depth": 100,
    "min_relevance_score": 0.2,
    "max_final_sentences": 20,
    "use_sbert": True
}

pipeline = BeamFilterPipeline(config)
results = pipeline.run_pipeline(context, claim)
```

### **Task 3: Advanced Filtering**

```bash
# Enable advanced filtering features
python src/pipeline/cli.py \
    --use-sbert \
    --use-contradiction-detection \
    --use-nli \
    context.txt claim.txt output.json
```

### **Task 4: Output Files**

The pipeline generates **3 types of output files**:

```bash
# Run pipeline
python run_pipeline.py --input raw_test.json --min_relevance 0.15

# Output files generated:
# â€¢ raw_test_beam_filtered_0.15_20241201_143022_detailed.json
# â€¢ raw_test_beam_filtered_0.15_20241201_143022_simple.json  
# â€¢ raw_test_beam_filtered_0.15_20241201_143022_stats.json
```

**File Types:**
- **Detailed**: Detailed information about the processing process
- **Simple**: Only list of evidence sentences
- **Stats**: Overview statistics about processing

## ğŸ—ï¸ **Project Architecture**

### **Core Components**

```
src/                           # Refactored modules
â”œâ”€â”€ utils/                     # Text preprocessing utilities
â”‚   â””â”€â”€ text_preprocessor.py   # Text cleaning & sentence splitting
â”œâ”€â”€ nlp/                       # NLP wrapper
â”‚   â””â”€â”€ vncorenlp_wrapper.py  # VnCoreNLP integration
â”œâ”€â”€ graph/                     # Simplified graph
â”‚   â””â”€â”€ text_graph_simple.py  # TextGraph for pipeline
â”œâ”€â”€ filtering/                 # Filter wrapper
â”‚   â””â”€â”€ filter_wrapper.py     # AdvancedDataFilter wrapper
â””â”€â”€ pipeline/                  # Main pipeline
    â”œâ”€â”€ beam_filter_pipeline.py # Main pipeline class
    â””â”€â”€ cli.py                # CLI interface

mint/                          # Original modules (preserved)
â”œâ”€â”€ text_graph.py             # Full-featured graph
â”œâ”€â”€ beam_search.py            # Beam search algorithm
â””â”€â”€ helpers.py                # Helper functions

advanced_data_filtering.py     # Advanced filtering system
```

### **Workflow Architecture**

```
Input Text â†’ Preprocessing â†’ NLP Annotation â†’ Graph Building â†’ Beam Search â†’ Filtering â†’ Output
     â†“              â†“              â†“              â†“              â†“           â†“
  Clean Text   VnCoreNLP    Text Graph    Path Finding   Relevance   Final Sentences
```

## ğŸ“š **Comprehensive Documentation**

* **[ğŸ“– Complete Documentation](docs/README_INDEX.md)**: Full documentation index
* **[ğŸ—ï¸ Architecture Overview](README_REFACTORED.md)**: Project architecture details
* **[ğŸ§  VnCoreNLP Setup](docs/VNCORENLP_SETUP.md)**: Vietnamese NLP installation guide
* **[ğŸ”§ Module Documentation](docs/)**: Individual module documentation
* **[ğŸ“š Original Files](docs/README_ORIGINAL_FILES.md)**: Migration and backward compatibility

## ğŸ¯ **Use Cases**

### **Fact-Checking Pipeline**
```python
# Extract relevant sentences for fact-checking
pipeline = BeamFilterPipeline()
results = pipeline.run_pipeline(context, claim)
relevant_sentences = results["final_sentences"]
```

### **Information Retrieval**
```python
# Find sentences related to a specific claim
config = {"beam_width": 60, "max_depth": 150}
pipeline = BeamFilterPipeline(config)
results = pipeline.run_pipeline(context, query)
```

### **Text Analysis**
```python
# Analyze text structure and relationships
from src.graph.text_graph_simple import TextGraphSimple
graph = TextGraphSimple()
# ... build and analyze graph
```

### **Batch Processing**
```bash
# Process multiple files
for file in contexts/*.txt; do
    python src/pipeline/cli.py "$file" claims/$(basename "$file") output/$(basename "$file" .txt).json
done
```

## ğŸ”§ **Configuration**

### **Environment Setup**

```bash
# Clone repository
git clone <repository-url>
cd BeamSearchFillter

# Install dependencies
pip install -r requirements.txt

# Setup environment
cp .env.example .env
# Edit .env and add your OpenAI API key if needed

# Optional: Install VnCoreNLP for Vietnamese processing
# See [VnCoreNLP Setup Guide](docs/VNCORENLP_SETUP.md)
# Or use auto setup: ./setup_vncorenlp.sh
```

### **Pipeline Configuration**

```python
config = {
    "beam_width": 40,              # Beam search width
    "max_depth": 120,              # Maximum search depth
    "max_paths": 200,              # Maximum paths to find
    "min_relevance_score": 0.15,   # Minimum relevance for filtering
    "max_final_sentences": 30,     # Maximum final sentences
    "use_sbert": False,            # Enable SBERT filtering
    "use_contradiction_detection": False,  # Enable contradiction detection
    "use_nli": False,              # Enable NLI stance detection
    "enable_pos_filtering": True,  # Enable POS tag filtering
    "important_pos_tags": {"N", "Np", "V", "A", "Nc", "M", "R", "P"}
}
```

### **CLI Options**

```bash
python src/pipeline/cli.py \
    --beam-width 50 \
    --max-depth 100 \
    --min-relevance 0.2 \
    --max-final-sentences 20 \
    --use-sbert \
    context.txt claim.txt output.json
```

## ğŸ› ï¸ **Advanced Features**

### **Implemented Capabilities**

* âœ… **Vietnamese NLP Processing**: Full VnCoreNLP integration
* âœ… **Graph-based Search**: NetworkX text graph with beam search
* âœ… **Multi-stage Filtering**: SBERT, contradiction, NLI filtering
* âœ… **Modular Architecture**: Clean separation of concerns
* âœ… **CLI Interface**: Complete command-line tools
* âœ… **Python API**: Flexible programming interface
* âœ… **Error Handling**: Comprehensive error handling and fallbacks
* âœ… **Documentation**: Complete documentation with examples

### **Research Applications**

* **Fact-checking Research**: Extract relevant evidence from large texts
* **Information Retrieval**: Find related sentences for specific queries
* **Text Analysis**: Analyze text structure and relationships
* **Vietnamese NLP**: Study Vietnamese text processing techniques

## ğŸ“ˆ **Output Formats**

The pipeline generates **3 types of output files** with filename format: `{input_name}_beam_filtered_{min_relevance}_{timestamp}_{type}.json`

### **1. Detailed Output** (`*_detailed.json`)
Contains detailed information about the processing process:
```json
[
  {
    "context": "Original context text",
    "claim": "Original claim text",
    "multi_level_evidence": [
      {
        "sentence": "Final sentence 1",
        "relevance_score": 0.92,
        "beam_score": 0.85,
        "path": ["claim_0", "word_1", "sentence_0"]
      }
    ],
    "statistics": {
      "beam": {
        "total_paths": 15,
        "unique_sentences": 25
      }
    }
  }
]
```

### **2. Simple Output** (`*_simple.json`)
Contains simple results, only evidence sentences:
```json
[
  {
    "context": "Original context text",
    "claim": "Original claim text",
    "multi_level_evidence": [
      "Final sentence 1",
      "Final sentence 2",
      "Final sentence 3"
    ]
  }
]
```

### **3. Statistics Output** (`*_stats.json`)
Contains overview statistics about the processing process:
```json
{
  "total_context_sentences": 1000,
  "total_beam_sentences": 500,
  "total_final_sentences": 150,
  "num_samples": 50,
  "beam_parameters": {
    "beam_width": 40,
    "max_depth": 120,
    "max_paths": 200,
    "beam_sentences": 50
  }
}
```

### **Console Output**
```
ğŸ”§ Beam Search Filter Pipeline - Default Run
=====================================

ğŸ“ Input:
Context: [context text]
Claim: [claim text]

ğŸ”„ Running pipeline...
âœ… Pipeline completed successfully

ğŸ“Š Results:
- Found relevant sentences
- Graph built successfully
- Beam search completed
- Filtering applied

ğŸ¯ Final Sentences:
1. [relevant sentence 1]
2. [relevant sentence 2]

âœ… Done! Output saved to:
   â€¢ [output files]
```

## ğŸ”— **Dependencies**

### **Required**
- `networkx`: Graph data structure
- `typing`: Type hints
- `argparse`: Command-line argument parsing
- `mint.beam_search`: Beam search algorithm (existing)
- `advanced_data_filtering`: Filter system (existing)

### **Optional**
- `py_vncorenlp`: Vietnamese NLP toolkit
- `vncorenlp/`: VnCoreNLP models directory
- `sentence-transformers`: For SBERT filtering
- `transformers`: For NLI and contradiction detection

## ğŸ§ª **Testing**

### **Quick Test**
```bash
# Test basic functionality
python run_pipeline.py

# Test CLI
python src/pipeline/cli.py test_context.txt test_claim.txt test_output.json
```

### **Comprehensive Test**
```bash
# Test with examples
python example_usage.py
```

## ğŸ” **Troubleshooting**

### **Common Issues**

**1. VnCoreNLP not available:**
```bash
# Check VnCoreNLP installation
ls -la vncorenlp/
python -c "from py_vncorenlp import py_vncorenlp; print('VnCoreNLP available')"
```

**2. AdvancedDataFilter not found:**
```bash
# Check if file exists
ls -la advanced_data_filtering.py
```

**3. Memory issues:**
```python
# Reduce parameters
config = {
    "beam_width": 20,
    "max_depth": 60,
    "max_paths": 100,
    "max_final_sentences": 15
}
```

## ğŸ“ **Contributing**

Beam Search Filter Pipeline welcomes contributions in:

* **New filtering methods**: Additional sentence filtering algorithms
* **Graph algorithms**: Novel beam search approaches
* **Vietnamese NLP**: Enhanced text processing techniques
* **Evaluation metrics**: Advanced relevance measures
* **Performance optimization**: More efficient processing patterns

### **Code Style**
- Follow existing module structure
- Use type hints
- Include comprehensive error handling
- Add documentation for new functions

## ğŸ“ **Support**

* **Documentation**: [docs/README_INDEX.md](docs/README_INDEX.md)
* **Issues**: Check troubleshooting sections in module docs
* **Migration**: See [docs/README_ORIGINAL_FILES.md](docs/README_ORIGINAL_FILES.md)

## ğŸ“œ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

ğŸš€ **Happy Vietnamese Text Processing!** Whether you're doing fact-checking research, information retrieval, or Vietnamese NLP development, Beam Search Filter Pipeline provides comprehensive tools for Vietnamese text intelligence research.

## About

> **Comprehensive Vietnamese text processing framework for fact-checking and information retrieval using beam search and advanced filtering techniques**

### Topics

- `nlp` - Natural Language Processing
- `vietnamese` - Vietnamese language processing
- `fact-checking` - Fact verification and validation
- `beam-search` - Graph-based search algorithms
- `text-filtering` - Advanced text filtering techniques

### Resources

- [ğŸ“– Complete Documentation](docs/README_INDEX.md)
- [ğŸ—ï¸ Architecture Overview](README_REFACTORED.md)
- [ğŸ§  VnCoreNLP Setup](docs/VNCORENLP_SETUP.md)

### License

MIT license 